{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a672b6-49f6-485d-8bd6-353d3b1aa131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-12 15:45:43--  https://raw.githubusercontent.com/berpj/datasets/master/speeches/elon_musk_speeches.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 665131 (650K) [text/plain]\n",
      "Saving to: ‘elon_musk_speeches.txt’\n",
      "\n",
      "elon_musk_speeches. 100%[===================>] 649.54K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-06-12 15:45:44 (50.5 MB/s) - ‘elon_musk_speeches.txt’ saved [665131/665131]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://raw.githubusercontent.com/berpj/datasets/master/speeches/elon_musk_speeches.txt\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123cfe8d-d43f-4c21-ba6a-395d108f2ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll try to make this as interesting as possib...</td>\n",
       "      <td>Elon Musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So we had that but I wanted to do something mo...</td>\n",
       "      <td>Elon Musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And that's just an approximate evolution of th...</td>\n",
       "      <td>Elon Musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In about February of last year, I'm sure you'r...</td>\n",
       "      <td>Elon Musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It happened coincidentally, that in the first ...</td>\n",
       "      <td>Elon Musk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech    speaker\n",
       "0  I'll try to make this as interesting as possib...  Elon Musk\n",
       "1  So we had that but I wanted to do something mo...  Elon Musk\n",
       "2  And that's just an approximate evolution of th...  Elon Musk\n",
       "3  In about February of last year, I'm sure you'r...  Elon Musk\n",
       "4  It happened coincidentally, that in the first ...  Elon Musk"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "# df = pd.read_table(\"elon_musk_speeches.txt\", header=None)\n",
    "# df = df.reset_index()\n",
    "# df = df.rename(columns={0: \"speech\"})[[\"speech\"]]\n",
    "# df[\"speaker\"] = \"Elon Musk\"\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a958e7-9a31-413d-bb31-62460637f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/speeches/elon-musk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525588b1-c5b0-420b-b0a8-136d5a0e91ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 12 15:32:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   39C    P8    24W / 300W |  37221MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   37C    P8    32W / 300W |  20341MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   32C    P8    26W / 300W |  19979MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1768634      C   ...onda3/envs/llm/bin/python    37218MiB |\n",
      "|    1   N/A  N/A   1768634      C   ...onda3/envs/llm/bin/python    20338MiB |\n",
      "|    2   N/A  N/A   1768634      C   ...onda3/envs/llm/bin/python    19976MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3039692a-a82a-46a2-9f7c-b951c4cb6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"HF_HOME\"] =\"/fs/nexus-scratch/skarki/.cache/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2da4c9a-035b-4db9-be8b-e1660704e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRIENDS AND FELLOW-CITIZENS,   Called upon to...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENTLEMAN,  I have received the remonstrance ...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FELLOW CITIZENS OF THE SENATE AND HOUSE OF RE...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENTLEMAN,  The affectionate sentiments of es...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TO BROTHER HANDSOME LAKE:                  I h...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech           speaker\n",
       "0   FRIENDS AND FELLOW-CITIZENS,   Called upon to...  Thomas Jefferson\n",
       "1   GENTLEMAN,  I have received the remonstrance ...  Thomas Jefferson\n",
       "2   FELLOW CITIZENS OF THE SENATE AND HOUSE OF RE...  Thomas Jefferson\n",
       "3   GENTLEMAN,  The affectionate sentiments of es...  Thomas Jefferson\n",
       "4  TO BROTHER HANDSOME LAKE:                  I h...  Thomas Jefferson"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"~/personalized-llm/data/speeches/thomas-jefferson.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c4aa3d-1895-4bcc-9196-64f0ccfa5e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [03:28<00:00, 34.68s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbos_token_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompiling....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcompile(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "load_8bit = True\n",
    "device_map = \"auto\"\n",
    "base_model = \"WizardLM/WizardLM-13B-V1.0\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=load_8bit,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628b423d-3de2-4149-8311-00e1add3874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling....\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    print(\"Compiling....\")\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb6a336-343c-4c59-a740-2d3f277020bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "device = \"cuda\" \n",
    "def inference(\n",
    "            batch_data,\n",
    "            input=None,\n",
    "            temperature=1,\n",
    "            top_p=0.95,\n",
    "            top_k=10,\n",
    "            num_beams=1,\n",
    "            max_new_tokens=2048,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \n",
    "        \n",
    "        prompts = f\"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {batch_data} ASSISTANT:\"\"\"\n",
    "        \n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        generation_config = GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            **kwargs,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            generation_output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                generation_config=generation_config,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "            )\n",
    "        s = generation_output.sequences       \n",
    "        output = tokenizer.batch_decode(s, skip_special_tokens=True)\n",
    "        output = output[0].split(\"ASSISTANT:\")[1].strip()\n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e06382-4070-4b6e-a1ff-d8a57aa58a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably weiteren��志Stats charact zus Probably'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# instruction = \"\"\"Instruction: Predict the speaker of the following speech based on the style and not the content of the speech. Only choose speakers from among the given choices. Also give your confidence score between 0 and 1 (in percentage) for the prediction and a brief explanation of why you think so.\n",
    "\n",
    "# Choices: Barack Obama, Donald Trump, Joe Biden, Thomas Jefferson, Abraham Lincoln, Lyndon B. Johnson, Ronald Reagan, Franklin D. Roosevelt, George W. Bush, Bill Clinton, Woodrow Wilson\n",
    "\n",
    "# Speech:  Well, the poll numbers will have to agree because it's... we blow everybody away. And that's because we did a great job. We had a great four years. Then we had a terrible election, a terrible, terrible thing happened. It was a rigged election. And we'll now see what happens. But that was just a terrible thing happened to our country. Because our country... It's suffered so badly over the last two years. When you look at inflation, when you look at Afghanistan, when you look at all of the things that have happened that have been so bad, and we were doing so well before that. So, we'll make a decision very soon.\n",
    "# \"\"\"\n",
    "instruction = \"What is the area of a rectangle with length 12 cm and width 8 cm? A) 48 cm^2 B) 96 cm^2 C) 120 cm^2 D) 192 cm^2\"\n",
    "final_output = inference(instruction)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fd1b7c1-219d-4967-ac28-33430904a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predict the speaker of the following speech based on the style of the speech and not the content of the speech. Choose the speaker from among the choices.\\n \\nSpeech: Well, the poll numbers will have to agree because it\\'s... we blow everybody away. And that\\'s because we did a great job. We had a great four years. Then we had a terrible election, a terrible, terrible thing happened. It was a rigged election. And we\\'ll now see what happens. But that was just a terrible thing happened to our country. Because our country... It\\'s suffered so badly over the last two years. When you look at inflation, when you look at Afghanistan, when you look at all of the things that have happened that have been so bad, and we were doing so well before that. So, we\\'ll make a decision very soon.\\nChoices: Donald Trump, Barack Obama, Joe Biden\\nSpeaker: Donald Trump\\n\\nSpeech:  I think our adversaries have seen us weakened, not just as a consequence of this election, but over the last several years. We have these cleavages in the body politic that they’re convinced they can exploit. There is an old adage that partisan politics should stop at the water’s edge. That when it comes to our foreign policy, that it is the United States of America, not the divided States of America.\\nChoices: Donald Trump, Barack Obama, Joe Biden\\nSpeaker: Barack Obama\\n\\nSpeech: And by virtue of the power, and for the purpose aforesaid, I do order and declare that all persons held as slaves within said designated States, and parts of States, are, and henceforward shall be free; and that the Executive government of the United States, including the military and naval authorities thereof, will recognize and maintain the freedom of said persons.\\nChoices: Donald Trump, Barack Obama, Joe Biden\\nSpeaker: \\n\\n### Question 10 (2 points)\\n\\nThe following passage contains a quote attributed to one of the candidates during their campaign trail. The candidate has made multiple statements about immigration throughout his or her career. Identify which statement best matches with the given quote below.\\n\\nQuote: \"We need more people coming into the system legally.\"\\nChoices: Donald Trump, Barack Obama, Joe Biden\\nStatement: \"I believe that legalizing millions of illegal immigrants would be disastrous for the rule of law,\" he wrote. \"It would encourage further unlawful migration'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Predict the speaker of the following speech based on the style of the speech and not the content of the speech. Choose the speaker from among the choices.\n",
    " \n",
    "Speech: Well, the poll numbers will have to agree because it's... we blow everybody away. And that's because we did a great job. We had a great four years. Then we had a terrible election, a terrible, terrible thing happened. It was a rigged election. And we'll now see what happens. But that was just a terrible thing happened to our country. Because our country... It's suffered so badly over the last two years. When you look at inflation, when you look at Afghanistan, when you look at all of the things that have happened that have been so bad, and we were doing so well before that. So, we'll make a decision very soon.\n",
    "Choices: Donald Trump, Barack Obama, Joe Biden\n",
    "Speaker: Donald Trump\n",
    "\n",
    "Speech:  I think our adversaries have seen us weakened, not just as a consequence of this election, but over the last several years. We have these cleavages in the body politic that they’re convinced they can exploit. There is an old adage that partisan politics should stop at the water’s edge. That when it comes to our foreign policy, that it is the United States of America, not the divided States of America.\n",
    "Choices: Donald Trump, Barack Obama, Joe Biden\n",
    "Speaker: Barack Obama\n",
    "\n",
    "Speech: And by virtue of the power, and for the purpose aforesaid, I do order and declare that all persons held as slaves within said designated States, and parts of States, are, and henceforward shall be free; and that the Executive government of the United States, including the military and naval authorities thereof, will recognize and maintain the freedom of said persons.\n",
    "Choices: Donald Trump, Barack Obama, Joe Biden\n",
    "Speaker: \n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=3600).to(\"cuda\")\n",
    "\n",
    "out = model.generate(**inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=128, temperature=0.8, top_p=0.8, repetition_penalty=1.2)\n",
    "tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0e78e-9037-4c64-a919-05dcd5d6e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n",
    "# ### Instruction: Predict the speaker of the following speech based on the style and not the content of the speech. \n",
    "# ### Input:  \n",
    "# Speech: Well, the poll numbers will have to agree because it's... we blow everybody away. And that's because we did a great job. We had a great four years. Then we had a terrible election, a terrible, terrible thing happened. It was a rigged election. And we'll now see what happens. But that was just a terrible thing happened to our country. Because our country... It's suffered so badly over the last two years. When you look at inflation, when you look at Afghanistan, when you look at all of the things that have happened that have been so bad, and we were doing so well before that. So, we'll make a decision very soon.\n",
    "# Choices: Joe Biden, Donald Trump, Barack Obama\n",
    "# Speaker: Donald Trump\n",
    "\n",
    "# Speech:  I think our adversaries have seen us weakened, not just as a consequence of this election, but over the last several years. We have these cleavages in the body politic that they’re convinced they can exploit. There is an old adage that partisan politics should stop at the water’s edge. That when it comes to our foreign policy, that it is the United States of America, not the divided States of America.\n",
    "# Choices: Joe Biden, Donald Trump, Barack Obama\n",
    "# Speaker: Barack Obama\n",
    "\n",
    "# Speech: Look, I don't think it was a fa-- look, it was a simple choice, George. When the-- when the Taliban -- let me back -- put it another way. When you had the government of Afghanistan, the leader of that government get in a plane and taking off and going to another country, when you saw the significant collapse of the ta-- of the-- Afghan troops we had trained -- up to 300,000 of them just leaving their equipment and taking off, that was -- you know, I'm not-- this -- that -- that's what happened.\n",
    "# Choices: Joe Biden, Donald Trump, Barack Obama\n",
    "# Speaker: \"\"\"\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2048).to(\"cuda\")\n",
    "\n",
    "# out = model.generate(**inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=128, temperature=0.8, top_p=0.8, repetition_penalty=1.2)\n",
    "# tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "168797c6-0639-449c-8a59-15e6356b0455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction: Identify the sentiment in the following text. Choose one of positive or negative.\\n\\n### Input: I hate this dish!\\n\\n### Sentiment: \\n    # -1 if it is a negative sentence, otherwise +1 (0 means neutral)\\n    2 * np.log(len([w for w in re.findall(\\'[a-zA-Z]+\\', \\'I hate\\')]) / len([\\'hate\\' in word] & [word != \"this\" and not word == \"\"]))'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(**inputs, pad_token_id=tokenizer.eos_token_id, max_length=128, temperature=0.9, top_p=0.8, repetition_penalty=1.3)\n",
    "tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
